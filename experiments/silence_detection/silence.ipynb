{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bujakowskih/uni/RNN/rnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "from math import ceil\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "speech_data = load_dataset(\n",
    "    \"speech_commands\", \"v0.02\", cache_dir=\"only_selected/data_here\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def compute_mfcc(data, sample_rate=16000, n_mfcc=12):\n",
    "    # Extract MFCC features\n",
    "    # https://librosa.github.io/librosa/generated/librosa.feature.mfcc.html\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=data,\n",
    "        sr=sample_rate,\n",
    "        n_mfcc=n_mfcc,  # How many mfcc features to use? 12 at most.\n",
    "        # https://dsp.stackexchange.com/questions/28898/mfcc-significance-of-number-of-features\n",
    "    )\n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def extract_fields(example):\n",
    "    x = example[\"audio\"][\"array\"]\n",
    "    return {\n",
    "        \"label\": example[\"label\"],\n",
    "        \"array\": np.pad(x, (0, 16000 - len(x)), constant_values=0),\n",
    "    }\n",
    "\n",
    "def cut_audio(example):\n",
    "\n",
    "    if len(example[\"audio\"][\"array\"]) >= 16000:\n",
    "        example[\"audio\"][\"array\"] = example[\"audio\"][\"array\"][:16000]\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "def split_audio(example, duration=1):\n",
    "    audio = example[\"audio\"][\"array\"]\n",
    "    sr = 16_000\n",
    "    n_samples = len(audio)\n",
    "    n_samples_per_chunk = sr * duration\n",
    "    n_chunks = ceil(n_samples / n_samples_per_chunk)\n",
    "    chunks = []\n",
    "    for i in range(n_chunks):\n",
    "        start = i * n_samples_per_chunk\n",
    "        end = (i + 1) * n_samples_per_chunk\n",
    "        chunk = audio[start:end]\n",
    "        if len(chunk) < n_samples_per_chunk:\n",
    "            chunk = np.pad(chunk, (0, n_samples_per_chunk - len(chunk)))\n",
    "        chunks.append(chunk)\n",
    "    return np.array(chunks)\n",
    "\n",
    "\n",
    "def create_new_data(data):\n",
    "    new_records = []\n",
    "    for silence_record in data:\n",
    "        temp = split_audio(silence_record)\n",
    "\n",
    "        for record in temp:\n",
    "            data_row = {\n",
    "                \"file\": [silence_record[\"file\"]],\n",
    "                \"audio\": [{\n",
    "                    \"array\": record,\n",
    "                    \"path\": silence_record[\"audio\"][\"path\"],\n",
    "                    \"sampling_rate\": silence_record[\"audio\"][\"sampling_rate\"],\n",
    "                }],\n",
    "                \"label\": [silence_record[\"label\"]],\n",
    "                \"is_unknown\": [silence_record[\"is_unknown\"]],\n",
    "                \"speaker_id\": [silence_record[\"speaker_id\"]],\n",
    "                \"utterance_id\": [silence_record[\"utterance_id\"]]\n",
    "            }\n",
    "            new_records.append(data_row)\n",
    "    return new_records\n",
    "\n",
    "\n",
    "def swap_labels_for_data_split(data):\n",
    "    # map the labels: 0 if <35 else 1\n",
    "    data = data.map(lambda x: {\"label\": 0 if x[\"label\"] < 35 else 1})\n",
    "    # split audio when label is 1\n",
    "    silence = data.filter(lambda x: x[\"label\"] == 1)\n",
    "    # create new data with split audio\n",
    "    temp = create_new_data(silence)\n",
    "    for el in temp:\n",
    "        silence = concatenate_datasets([Dataset.from_dict(el, features=silence.features), silence])\n",
    "    data = concatenate_datasets([data.filter(lambda x: x[\"label\"] == 0), silence])\n",
    "    data = data.map(cut_audio)\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(speech_data):\n",
    "    train = speech_data[\"train\"]\n",
    "    validation = speech_data[\"validation\"]\n",
    "    test = speech_data[\"test\"]\n",
    "\n",
    "    train = swap_labels_for_data_split(train)\n",
    "    validation = swap_labels_for_data_split(validation)\n",
    "    test = swap_labels_for_data_split(test)\n",
    "\n",
    "\n",
    "    train_silence = train.filter(lambda x: x[\"label\"] == 1)\n",
    "    train_no_silence = train.filter(lambda x: x[\"label\"] == 0)\n",
    "    train_no_silence = train_no_silence.shuffle(seed=42).select(range(len(train_silence) * 2))\n",
    "\n",
    "    train = concatenate_datasets([train_no_silence, train_silence])\n",
    "\n",
    "    train = train.map(\n",
    "        extract_fields, remove_columns=[\"file\", \"audio\", \"speaker_id\", \"utterance_id\"]\n",
    "    )\n",
    "    validation = validation.map(\n",
    "        extract_fields, remove_columns=[\"file\", \"audio\", \"speaker_id\", \"utterance_id\"]\n",
    "    )\n",
    "    test = test.map(\n",
    "        extract_fields, remove_columns=[\"file\", \"audio\", \"speaker_id\", \"utterance_id\"]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train.with_format(\"torch\"),\n",
    "        validation.with_format(\"torch\"),\n",
    "        test.with_format(\"torch\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train, validation, test = preprocess(speech_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class SilenceModel(nn.Module):\n",
    "    def __init__(self, input_size=12, hidden_size=64, num_layers=3, output_size=2):\n",
    "        super(SilenceModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, dropout=0.15\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc2(self.relu(self.fc(out[:, -1, :])))\n",
    "        return out\n",
    "\n",
    "def calculate_accuracy(preds, y):\n",
    "    preds = torch.nn.functional.softmax(preds, dim=1)\n",
    "    preds = torch.argmax(preds, dim=1)\n",
    "    return (torch.sum(preds == y) / len(y)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:20<06:29, 20.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.6971408619600183, train accuracy: 0.49131016170277314 val loss: 0.6404100292047877, val accuracy: 0.9805069002233873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:40<06:01, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train loss: 0.6277366806479061, train accuracy: 0.8018048160216388 val loss: 0.4096057209998939, val accuracy: 0.9930334394904459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:00<05:41, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train loss: 0.4973644824589, train accuracy: 0.8155915807275211 val loss: 0.20379060658679646, val accuracy: 0.9923367834394905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:20<05:19, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train loss: 0.4148288176340215, train accuracy: 0.8551136395510506 val loss: 0.22696271329928355, val accuracy: 0.9906449044585988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:40<04:59, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train loss: 0.3084099770468824, train accuracy: 0.8841911764705882 val loss: 0.1337330299103336, val accuracy: 0.9716361464968153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:59<04:37, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train loss: 0.09974124162074398, train accuracy: 0.9715073529411765 val loss: 0.122590503685034, val accuracy: 0.9643710191082803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:19<04:18, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train loss: 0.06237641146735234, train accuracy: 0.9871323529411765 val loss: 0.09236824759252511, val accuracy: 0.9786027070063694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:39<03:56, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train loss: 0.05373248849611949, train accuracy: 0.9862132352941176 val loss: 0.07284360306017149, val accuracy: 0.9806926751592356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:58<03:36, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train loss: 0.031512798029271996, train accuracy: 0.9926470588235294 val loss: 0.05261510595750467, val accuracy: 0.986265923566879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:18<03:17, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train loss: 0.02608255488688455, train accuracy: 0.9935661764705882 val loss: 0.04392614586806744, val accuracy: 0.9903463375796179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:38<02:59, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 train loss: 0.02175150765106082, train accuracy: 0.9917279411764706 val loss: 0.05914299606173566, val accuracy: 0.9839769108280255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:58<02:38, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 train loss: 0.02573767935802393, train accuracy: 0.9944852941176471 val loss: 0.04141574316349616, val accuracy: 0.991640127388535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [04:18<02:18, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 train loss: 0.019618729992276606, train accuracy: 0.9917279411764706 val loss: 0.10248683459736455, val accuracy: 0.969081740992464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [04:38<01:59, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 train loss: 0.01766585383345099, train accuracy: 0.9963235294117647 val loss: 0.058078505020220855, val accuracy: 0.9852707006369427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:57<01:38, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 train loss: 0.009229441762299222, train accuracy: 0.9981617647058824 val loss: 0.062147755774218515, val accuracy: 0.9831940021342153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [05:18<01:20, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 train loss: 0.007417183657012442, train accuracy: 0.9972426470588235 val loss: 0.05665045276144816, val accuracy: 0.9846802017040504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:38<01:00, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 train loss: 0.00668832372791846, train accuracy: 0.9981617647058824 val loss: 0.07578076248184724, val accuracy: 0.9805069002233873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:58<00:40, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 train loss: 0.01557174013749532, train accuracy: 0.9928141727167017 val loss: 0.07148109919912105, val accuracy: 0.9815021231533236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [06:19<00:20, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 train loss: 0.018609817143228343, train accuracy: 0.9898897058823529 val loss: 0.07163513208751324, val accuracy: 0.9746947983267961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:40<00:00, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 train loss: 0.013493874137673308, train accuracy: 0.9944852941176471 val loss: 0.039693933522705414, val accuracy: 0.9829087049053733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = 12\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 2\n",
    "\n",
    "model = SilenceModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "NUM_EPOCHS = 20\n",
    "SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer=optimizer, T_max=NUM_EPOCHS, eta_min=0\n",
    ")\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "results = pd.DataFrame(\n",
    "                columns=[\n",
    "                    \"epoch\",\n",
    "                    \"train_loss\",\n",
    "                    \"train_accuracy\",\n",
    "                    \"val_loss\",\n",
    "                    \"val_accuracy\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(validation, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE)\n",
    "\n",
    "for epoch in tqdm(range(1, NUM_EPOCHS + 1)):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch in train_loader:\n",
    "        x = batch[\"array\"]\n",
    "        x = (\n",
    "            torch.Tensor(compute_mfcc(np.array(x), 16_000))\n",
    "            .permute(0, 2, 1)\n",
    "            .to(device)\n",
    "        )\n",
    "        y = batch[\"label\"].to(device)\n",
    "        y_pred = model(x.float())\n",
    "        loss = criterion(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_accuracy += calculate_accuracy(y_pred, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_accuracy / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        for batch in valid_loader:\n",
    "            x = batch[\"array\"]\n",
    "            x = (\n",
    "                torch.Tensor(compute_mfcc(np.array(x), 16_000))\n",
    "                .permute(0, 2, 1)\n",
    "                .to(device)\n",
    "            )\n",
    "            y = batch[\"label\"].to(device)\n",
    "            y_pred = model(x.float())\n",
    "            val_loss += criterion(y_pred, y).item()\n",
    "            val_accuracy += calculate_accuracy(y_pred, y)\n",
    "        val_loss /= len(valid_loader)\n",
    "        val_accuracy = val_accuracy / len(valid_loader)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        row = pd.DataFrame(\n",
    "            {\n",
    "                \"epoch\": [epoch],\n",
    "                \"train_loss\": [loss.item()],\n",
    "                \"train_accuracy\": [train_accuracy],\n",
    "                \"val_loss\": [val_loss],\n",
    "                \"val_accuracy\": [val_accuracy],\n",
    "            }\n",
    "        )\n",
    "        results = pd.merge(results, row, how=\"outer\")\n",
    "    print(\n",
    "        f\"Epoch {epoch} train loss: {train_loss}, train accuracy: {train_accuracy} val loss: {val_loss}, val accuracy: {val_accuracy}\"\n",
    "    )\n",
    "results.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9654292169823704\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_accuracy = 0.0\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[\"array\"]\n",
    "        x = (\n",
    "            torch.Tensor(compute_mfcc(np.array(x), 16_000))\n",
    "            .permute(0, 2, 1)\n",
    "            .to(device)\n",
    "        )\n",
    "        y = batch[\"label\"].to(device)\n",
    "        y_pred = model(x.float())\n",
    "        test_accuracy += calculate_accuracy(y_pred, y)\n",
    "        predictions.append(y_pred)\n",
    "        true_labels.append(y)\n",
    "test_accuracy = test_accuracy / len(test_loader)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SilenceModel(\n",
       "  (lstm): LSTM(12, 64, num_layers=3, batch_first=True, dropout=0.15)\n",
       "  (fc): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = SilenceModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# load the model\n",
    "model2.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9654292169823704\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "test_accuracy = 0.0\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch[\"array\"]\n",
    "        x = (\n",
    "            torch.Tensor(compute_mfcc(np.array(x), 16_000))\n",
    "            .permute(0, 2, 1)\n",
    "            .to(device)\n",
    "        )\n",
    "        y = batch[\"label\"].to(device)\n",
    "        y_pred = model2(x.float())\n",
    "        test_accuracy += calculate_accuracy(y_pred, y)\n",
    "        predictions.append(y_pred)\n",
    "        true_labels.append(y)\n",
    "test_accuracy = test_accuracy / len(test_loader)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
